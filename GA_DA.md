# 生成方法（Generative approach）和判别方法（Discriminative approach）

>判别方法：由数据直接学习决策函数 $Y=f(X)$ 或者条件概率分布 $P(Y|X)$ 作为预测的模型，即判别模型。基本思想是有限样本条件下建立判别函数，不考虑样本的产生模型，直接研究预测模型。典型的判别模型包括k近邻，感知级，决策树，支持向量机等

>生成方法：由数据学习联合概率密度分布 $P(X,Y)$，然后求出条件概率分布 $P(Y|X)$ 作为预测的模型，即生成模型 $P(Y|X)=P(X,Y)/P(X)$

## 优缺点

- 生成方法

>生成方法学习联合概率密度分布 $P(X,Y)$，所以就可以从统计的角度表示数据的分布情况，能够反映同类数据本身的相似度。但它不关心到底划分各类的那个分类边界在哪。

>生成方法可以还原出联合概率分布，而判别方法不能。

>生成方法的学习收敛速度更快，即当样本容量增加的时候，学到的模型可以更快的收敛于真实模型，当存在隐变量时，仍可以用生成方法学习。此时判别方法就不能用。

- 判别方法

>判别方法直接学习的是决策函数 $Y=f(X)$ 或者条件概率分布 $P(Y|X)$。不能反映训练数据本身的特性。但它寻找不同类别之间的最优分类面，反映的是异类数据之间的差异。

>直接面对预测，往往学习的准确率更高。

>由于直接学习 $P(Y|X)$ 或 $P(X)$，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题。
